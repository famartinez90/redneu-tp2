\section{Resultados}
En esta sección incluiremos los resultados de la experimentación que realizamos con las redes desarrolladas.\\

La idea general de los experimentos es intentar medir la performance
de cada red observando, en el primer problema, la distribución espacial de los clusters de empresas y en el segundo, la calidad 
del mapa generado.\\

Presentamos en primer lugar los resultados obtenidos del problema de reducción de dimensiones.

\subsection{Ejercicio 1 - Reducción de dimensiones}

Para el primer ejercicio, los experimentos consistieron en variar la cantidad de épocas, la regla de aprendizaje y la cantidad de dimensiones de salida. Intentamos variar estos factores y observar diferencias en los gráficos 3D generados en base a las nuevas dimensiones.

Comenzamos realizando clasificaciones con 100 épocas. Al obtener resultados imprecisos subimos la cantidad a 200. Allí observamos una clasificación mejor, más marcada la separación geométrica entre los distintos clusters.

Luego comparamos los resultados obtenidos entre las distintas reglas. Repetimos las ejecuciones variando la regla entre Oja y Sanger para comprobar su eficacia.

Por último, decidimos cambiar la cantidad de dimensiones de sálida, esperando una mejora en las clasificaciones. 

\subsubsection{Regla de Oja - variando número de épocas}
En los primeros experimentos, fuimos probando la calidad de la clasificación utilizando solamente 100 épocas. La decisión se basó en un tema de performance de la red. Cada ejecución tenía una considerable demora, por lo que empezamos probando con pocas épocas. Mostramos los primeros resultados que obtuvimos, utilizando la regla de Oja:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_100ep_train_2.png}
  \caption{Oja - 3 dimensiones - 100 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_100ep_train_3.png}
  \caption{Oja - 3 dimensiones - 100 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\newpage

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.45]{../img/ej1/oja/oja_3salida_100ep_train.png}
  \caption{Oja - 3 dimensiones - 100 épocas - Datos Entrenamiento}
  \end{center}
\end{figure}

Éstos son los gráficos de las ejecuciones utilizando regla de Oja, con 100 épocas. Notamos que se están comenzando a formar
clusters de clasificación con distintos colores, pero que también hay mucho solapamiento en la parte central de cada vista.\\

Luego de esta etapa de entrenamiento, procesamos los datos de validación:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_100ep_validation.png}
  \caption{Oja - 3 dimensiones - 100 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_100ep_validation_3.png}
  \caption{Oja - 3 dimensiones - 100 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.65]{../img/ej1/oja/oja_3salida_100ep_validation_2.png}
  \caption{Oja - 3 dimensiones - 100 épocas - Datos Validación}
  \end{center}
\end{figure}

\newpage

Para los datos de validación vemos una dispersión muy grande. Se notan algunos puntos del mismo color agrupados levemente cerca, pero lejos
de formar una división clara.\\

Luego de obtener estos resultados, menos precisos de lo que esperábamos, decidimos intentar probar subiendo número de épocas. Observemos a continuación las mismas ejecuciones, pero subiendo el número de épocas a 200:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_train.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_train_2.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}
\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_train_3.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_train_4.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub4}
\end{subfigure}
\end{figure}

En los datos de entrenamiento se observa que con 200 épocas se empiezan a notar más visiblemente
los clusters de datos. Se observa una leve mejora en la clasificación con respecto a la versión de 100 épocas.

Podemos ver de todas formas que algunas de las categorías se encuentran mezcladas entre sí mientras otras están más claramente divididas.

A continuación los datos de validation.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_validation.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_validation_3.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.65]{../img/ej1/oja/oja_3salida_200ep_validation_2.png}
  \caption{Oja - 3 dimensiones - 200 épocas - Datos Validación}
  \end{center}
\end{figure}

En esta segunda tanda de gráficos se observa una mejora leve también para los datos de validación. Podemos ver que la mayoría de las marcas del mismo color están aproximadamente cercanas entre sí.

\subsubsection{Regla de Sanger - variando número de épocas}
Repetimos en este caso el experimento anterior utilizando ahora la regla de Sanger. Intentaremos comprobar si con esta nueva regla de aprendizaje
se obtienen mejores resultados variando el número de épocas.

En primer lugar, resultados con 100 épocas:

\newpage

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_100ep_train.png}
  \caption{Sanger - 3 dimensiones - 100 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_100ep_train_3.png}
  \caption{Sanger - 3 dimensiones - 100 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.45]{../img/ej1/sanger/sanger_3salida_100ep_train_2.png}
  \caption{Sanger - 3 dimensiones - 100 épocas - Datos Entrenamiento}
  \end{center}
\end{figure}

Éstos son los resultados de las ejecuciones utilizando regla de Sanger, con 100 épocas. Notamos un gran nivel de dispersión y 
solapamiento entre las categorías. No tienen la calidad que esperábamos.

Luego de esta etapa de entrenamiento, procesamos los datos de validación. No obtuvimos buenos resultados, las marcas están 
medianamente agrupadas pero con alto nivel de disgregación.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_100ep_validation.png}
  \caption{Sanger - 3 dimensiones - 100 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_100ep_validation_3.png}
  \caption{Sanger - 3 dimensiones - 100 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.65]{../img/ej1/sanger/sanger_3salida_100ep_validation_2.png}
  \caption{Sanger - 3 dimensiones - 100 épocas - Datos Validación}
  \end{center}
\end{figure}

\newpage

Para los datos de validación vemos, que al igual que en Oja, los resultados con solo 100 épocas no son los mejores.

Observemos a continuación las mismas ejecuciones, pero subiendo el número de épocas a 200:

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.75]{../img/ej1/sanger/sanger_3salida_200ep_train_2.png}
  \caption{Sanger - 3 dimensiones - 200 épocas - Datos Validación}
  \end{center}
\end{figure}

\newpage

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_train.png}
  \caption{Sanger - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_train_3.png}
  \caption{Sanger - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

En los datos de entrenamiento observamos que con 200 épocas los clusters de datos se encuentran un poco más definidos. 
Se observa una notable mejora en la clasificación con respecto a la versión anterior de 100 épocas.

Podemos ver de todas formas que algunas de las categorías presentan alto nivel de solapamiento.

A continuación los datos de validation.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_validation.png}
  \caption{Sanger - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_validation_3.png}
  \caption{Sanger - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.4]{../img/ej1/sanger/sanger_3salida_200ep_validation_2.png}
  \caption{Sanger - 3 dimensiones - 200 épocas - Datos Validación}
  \end{center}
\end{figure}

En esta segunda tanda de gráficos se observa una mejora leve también para los datos de validación. Podemos ver que la mayoría de las marcas del mismo color están aproximadamente cercanas entre sí.

Debido a la lenta performance de las pruebas con la red, continuar aumentando la cantidad de épocas se volvió inviable. De todas formas hicimos una prueba preliminar con 500 épocas para explorar la posibilidad de obtener mejores resultados. Éstos no fueron mejores que los presentados aquí con 200, por lo tanto no continuamos dicho experimento y nos quedamos con las 200.
\newpage
\subsubsection{Regla de Oja - Variando número de dimensiones}

Dados los resultados obtenidos, intentamos buscar una forma de mejorar la precisión de la clasificación. Por sugerencia docente, decidimos intentar aumentar la dimensionalidad de la salida. En lugar de reducir a 3 dimensiones como pide el enunciado, subimos la cantidad a 9 dimensiones, esperando obtener mejores resultados. \\
Teniendo en cuenta la imposibilidad de graficar y observar espacialmente los resultados con 9 valores, partimos los vectores de salida y mostramos 3 espacios tridimensionales con 3 características cada uno. El procedimiento fue tomar las primeras 3 dimensiones de cada resultado, graficarlas en 3D, luego repetir con las siguientes 3 y continuar de esta forma con las últimas.

En este experimento solo mostraremos los resultados de las corridas de entrenamiento, ya que cuentan con un volumen de datos mayor y permiten apreciar mejor la división en clusters. A continuación mostraremos los resultados que obtuvimos para ambas reglas, utilizando 9 dimensiones de salida.

Comenzamos con las primeras tres coordenadas:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim123.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 123}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim123_2.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 123}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim123_3.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 123}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim123_4.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 123}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\newpage

En estas primeras 3 coordenadas, los clusters se encuentran muy entrelazados y mezclados, la clasificación no es clara. No se observan demasiadas mejoras
contra la versión de 3 dimensiones únicas.

Veamos las siguientes 3 coordenadas.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim456.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 456}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim456_2.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 456}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim456_3.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 456}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim456_4.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 456}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

Para las coordenadas 456 vemos que hay una mayor expansión del espacio ocupado por los datos y se nota un grado levemente mayor de separación entre
los puntos coloreados.

Veamos las siguientes 3 coordenadas.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim789.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 789}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim789_2.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 789}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim789_3.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 789}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja_corrida_200_9/oja_9salida_200ep_testing_dim789_4.png}
  \caption{Oja - 9 dimensiones - 200 épocas - Coordenadas 789}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

En las últimas coordenadas los resultados son similares a las 456. Se notan algunas zonas donde predominan cierta categoría, con bastante solapamiento en la zona central.
Los resultados no se muestran muy superiores a los obtenidos con solo 3 coordenadas totales.

Observemos las ejecuciones utilizando Regla de Sanger.

\subsubsection{Regla de Sanger - Variando número de dimensiones}

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim123.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 123}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim123_2.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 123}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim123_3.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 123}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim123_4.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 123}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

Usando la regla de Sanger se observan mucho mejores resultados. Se pueden observar los clusters separados con mucha mayor claridad. 

A continuación los resultados de las coordenadas 456:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim456.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 456}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim456_2.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 456}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim456_3.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 456}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim456_4.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 456}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

En esta tanda vemos nuevamente una clasificación más marcada y con mayor espacio entre los clusters. Se puede apreciar la agrupación
de las marcas del mismo color, mostrando la asociación entre documentos de la misma categoría.

Veamos las últimas 3 coordenadas.


\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim789.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 789}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim789_2.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 789}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim789_3.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 789}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger_corrida_200_9/sanger_9salida_200ep_testing_dim789_4.png}
  \caption{Sanger - 9 dimensiones - 200 épocas - Coordenadas 789}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

En estas últimas se nota menos precisión en los clusters y mayor solapamiento. Sin embargo, considerado lo observado con Sanger en las primeras 3 coordenadas, éstos son los mejores
resultados que obtuvimos en todo el ejercicio 1. En el caso de esta regla, la ampliación a 9 dimensiones mostró una diferencia notable en la calidad de la solución.

\newpage
\subsection{Ejercicio 2 - Mapeo de características}

Para el segundo ejercicio, los experimentos consistieron en variar la cantidad de neuronas del mapa que podían ser activadas, en conjunto con la cantidad de épocas y la división de las mismas en ordenamiento y convergencia. Intentamos variar estos factores y observar diferencias en los gráficos de estilo mapa de calor generados en base a las categorías que activaron en mayor medida a cada una de las neuronas del mapa.

Comenzamos realizando clasificaciones con 200 épocas como el primer ejercicio, pero, si bien se pudieron apreciar algunos agrupamientos, no era lo esperado. Dado que además vimos que corría mucho más rápido que en el primer ejercicio, decidimos además subir las épocas a 1000 como se propone en lo visto en clase. Allí observamos una clasificación mejor, con agrupamientos bien definidos.

Estas pruebas fueron hechas tanto para el mapeo de los documentos directamente (donde cada neurona del mapa tiene 850 vectores de entrada), y para las 3 y 9 componentes principales que se obtienen de las redes generadas en el primer ejercicio. Para estos dos últimos casos, utilizaremos las redes generadas con el algoritmo de Sanger, dado que fue el que nos devolvió los mejores resultados.

Finalmente, comparamos los resultados obtenidos entre las 3 opciones para dar nuestra visión de cual funcionó mejor en base a nuestros experimentos.

\subsubsection{Mapeo de documentos con 850 atributos}

En primera instancia, planteamos un experimento utilizando 200 épocas, lo cual no produjo buenos resultados como mencionamos anteriormente. En consecuencia, aumentamos las épocas a 1000 como sugerencia de lo visto en clase. Decidimos tomar un mapa de neuronas de 10 x 10 como primera prueba. Nos pareció un buen número para empezar para darle oportunidad a cada neurona de que sea activada por más de un documento (810 documentos de entrenamiento sobre 100 neuronas del mapa). 

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.4]{../img/map_1000ep_850en.png}
  \caption{Mapa 10x10 - 850 ejes x neurona - 1000 épocas - Sigma 5 - Entrenamiento}
  \end{center}
\end{figure}

Si bien hay un idea de agrupamiento no es lo que esperábamos, por lo cual decidimos variar el parámetro T1 del cálculo del sigma inicial para que la función logaritmo del sigma que nosotros pasamos por parámetro le aplique logaritmo en base 2 en vez de logaritmo natural. Luego, volvimos a correr el experimento y obtuvimos mejores resultados.

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.4]{../img/map_1000ep_850en_v2.png}
  \caption{Mapa 10x10 - 850 ejes x neurona - 1000 épocas - Sigma 5 - Entrenamiento}
  \end{center}
\end{figure}

Sin embargo, encontramos muy extraño que haya tantos blancos en el mapa, que significa que esas neuronas que están blancas no fueron activadas por ningún documento cuando realizamos la última pasada de los documentos sobre la red entrenada para armar el mapa. Esto nos desconcertó de si era correcto o no, con lo cual recurrimos a consultarlo con los profesores, lo que nos permitió entender que esto no debería suceder y que las posibles causas podían ser que nuestro mapa era demasiado grande, o que teníamos algún problema en la función de vecindad y/o las fases de ordenamiento y convergencia y/o nuestro código en sí.

Luego de revisar nuestra implementación, descubrimos que las fases de ordenamiento y convergencia no estaban muy bien definidas y que durante todas las épocas tanto el sigma como el eta no dejaban de ser \textit{enfriados}. Es por eso que decidimos plantear que de las 1000 épocas, dos tercios de las mismas sean de ordenamiento y el resto de convergencia. Además, decidimos achicar el área de nuestro mapa de neuronas de 10x10 a 8x8 y volvimos a correr el experimento con sigma 5 y con sigma 8.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/map8x8_1000ep_850en.png}
  \caption{Mapa 8x8 - 850 ejes x neurona - 1000 épocas - Sigma 5 - Entrenamiento}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/map8x8_1000ep_850en_sigma8.png}
  \caption{Mapa 8x8 - 850 ejes x neurona - 1000 épocas - Sigma 8 - Entrenamiento}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

Con los resultados podemos ver que la presencia de blancos disminuyo ligeramente pero siguen presentes, incluso aún no tenemos una clusterización perfecta que es lo que queremos lograr. Debido a que no estamos conformes con éstos resultados, decidimos ahora modificar la duración de las fases de ordenamiento y convergencia. Recordemos que hasta éste momento estábamos utilizando 2 tercios de la 1000 épocas para el ordenamiento y el tercio restante para convergencia (~333 épocas para convergencia). Ahora, en vez de eso, haremos pruebas con 1 medio (500 épocas) y 1 cuarto (250 épocas) para convergencia.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/map8x8_1000ep_850en_sigma8_faseord500.png}
  \caption{Mapa 8x8 - 850 ejes x neurona - 1000 épocas (500 ord/500 conv) - Sigma 8 - Entrenamiento}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/map8x8_1000ep_850en_sigma8_faseord750.png}
  \caption{Mapa 8x8 - 850 ejes x neurona - 1000 épocas (750 ord/250 conv) - Sigma 8 - Entrenamiento}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

Como se puede apreciar, el problema de clusterización se resuelve en su totalidad utilizando 750 épocas para el ordenamiento y 250 para la convergencia. Por otro lado, el problema de los blancos sigue presente, lo cual nos lleva nuevamente a replantear nuestros parámetros para eliminar este comportamiento en su totalidad. Es por eso que decidimos utilizar un mapa de neuronas más pequeño, de 7x7 en vez de 8x8. 

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.4]{../img/map7x7_1000ep_850en_sigma7_faseord750.png}
  \caption{Mapa 7x7 - 850 ejes x neurona - 1000 épocas (750 ord/250 conv) - Sigma 7 - Entrenamiento}
  \end{center}
\end{figure}

Ahora sí, en este experimento conseguimos los resultados esperados, con lo cual confirmamos que nuestro problema era que el mapa de neuronas estaba demasiado grande. Un detalle importante es que luego de realizar este experimento nos dimos cuenta que las categorías 8 y 9 estaban siendo coloreadas de la misma manera, con lo cual tuvimos que ajustar el mapa para que salga correctamente.

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.4]{../img/map7x7_1000ep_850en_sigma7_faseord750_corregido.png}
  \caption{Mapa 7x7 - 850 ejes x neurona - 1000 épocas (750 ord/250 conv) - Sigma 7 - Entrenamiento}
  \end{center}
\end{figure}

\newpage
\section{Soluciones Óptimas Propuestas}

% Siguiendo las distintas conclusiones que fuimos formando a través de los experimentos, generamos una solución óptima para cada ejercicio del TP. Estas soluciones se encuentran codificadas en \textbf{solucion\_ej1.json} y \textbf{solucion\_ej2.json}.

% \subsection{Ejercicio 1}
% La solución del ejercicio 1 fue generada con los siguientes parámetros:

% \texttt{\$python script.py 1 -ep=250 -capas=10,10 -eta=0.05 -estop=0.1}

% La solución generó muy buenos resultados, obteniendo 94\% de efectividad con respecto a su dataset de testing.
% Con respecto al error final, así fue su evolución:

% \begin{figure}[h]
%   \begin{center}
%   \includegraphics[scale=0.50]{graficos/solucion_ej1.png}
%   \caption{Evolución del error a través del entrenamiento para la solución 1}
%   \end{center}
% \end{figure}

% Notamos que encontró valores muy bajos de error, con una curva bastante pronunciada a partir de la época 50. Observamos que el early stopping efectivamente entró en efecto, ya que cortó la ejecución antes de llegar al límite de épocas.\\

% En caso de querer cargar y probar esta red, ejecutar:

% \texttt{\$python script.py 1 -file=F -rda=solucion\_ej1.json -te=100 }

% donde \texttt{F} debe ser el path al archivo CSV que contenga el dataset seleccionado. El parámetro $te=100$ implica que se le ordena a la red predecir todos los resultados del dataset como testing y calcular su tasa de aciertos.

% \subsection{Ejercicio 2}
% La solución del ejercicio 2 fue generada con los siguientes parámetros:

% \texttt{\$python script.py 2 -ep=250 -capas=7 -estop=0.05}

% La solución generó resultados decentes, obteniendo 74\% de efectividad con respecto a su dataset de testing.\\
% Se nota una eficiencia menor a la de la solución del ejercicio 1.
% En la última figura podemos ver la evolución de las épocas y el error:

% \begin{figure}[h]
%   \begin{center}
%   \includegraphics[scale=0.50]{graficos/solucion_ej2.png}
%   \caption{Evolución del error a través del entrenamiento para la solución 2}
%   \end{center}
% \end{figure}

% \newpage

% Notamos en este caso un descenso más lento del error y un estancamiento final en la curva. No se llegó a aplicar la cláusula del early stopping.


% En caso de querer cargar y probar esta red, ejecutar:

% \texttt{\$python script.py 2 -file=F -rda=solucion\_ej2.json -te=100 }

% donde \texttt{F} debe ser el path al archivo CSV que contenga el dataset seleccionado.

% \newpage
\section{Conclusión}

% Como conclusión podemos ver que los distintos ejercicios y sus características obtuvieron diferentes resultados en los experimentos realizados.\\

% Notamos en ellos algunos fenómenos. En primer lugar, parecería que la cantidad óptima de neuronas en cada capa se acerca a la cantidad de atributos a procesar por la red. Esto se pudo observar en el experimento de cantidad de neuronas para cada ejercicios.\\
% En segundo lugar, apreciamos distintos efectos en la cantidad de épocas necesarias para llegar a buenos resultados. Cada ejercicio necesitó una cantidad diferente y muchos de los parámetros afectaron dicha cantidad, aumentándola ampliamente en varios casos.\\

% Algunos parámetros que pensamos que tendrían mayor efecto en los resultados fueron los de distribución de los pesos, momentum y en el caso del ejercicio 2, cantidad de capas. Nos sorprendió que finalmente la solución óptima no utilizara más estos factores.\\

% Aprendimos que parámetros como el early stopping, que de antemano parecía que si o si debería estar en nuestra solución, no nos dió resultados lo suficiente buenos 
% como para considerarlo como algo obligatorio a la hora de entrenar la red. Quizás esto fue porque la cantidad de épocas de nuestro entrenamiento no era la suficiente 
% como vimos anteriormente, y este relacionado también con que nuestro conjunto de datos es acotado, nuestra red pequeña y no se necesitan tantas épocas para entrenar.

% Vimos también que los parámetros adaptativos, como el learning rate, mejoran considerablemente soluciones como el entrenamiento batch o mini batch. Incluso, en el 
% entrenamiento batch, se puede llegar a conseguir una soluciones muy buenas si las épocas son suficientes con learning rate adaptativo.

% Finalmente observamos la naturaleza práctica de este tipo de problemas, en la cual muchos de las decisiones responden a experimentación y pruebas y no tanto a fundamentos teóricos o conceptuales.
