\section{Resultados}
En esta sección incluiremos los resultados de la experimentación que realizamos con las redes desarrolladas.\\

La idea general de los experimentos es intentar medir la performance
de cada red observando, en el primer problema, la distribución espacial de los clusters de empresas y en el segundo, la calidad 
del mapa generado.\\

Presentamos en primer lugar los resultados obtenidos del problema de reducción de dimensiones.

\subsection{Ejercicio 1 - Reducción de dimensiones}

Para el primer ejercicio, los experimentos consistieron en variar la cantidad de épocas, la regla de aprendizaje y la cantidad de dimensiones de salida. Intentamos variar estos factores y observar diferencias en los gráficos 3D generados en base a las nuevas dimensiones.

Comenzamos realizando clasificaciones con 100 épocas. Al obtener resultados imprecisos subimos la cantidad a 200. Allí observamos una clasificación mejor, más marcada la separación geométrica entre los distintos clusters.

Luego comparamos los resultados obtenidos entre las distintas reglas. Repetimos las ejecuciones variando la regla entre Oja y Sanger para comprobar su eficacia.

Por último, decidimos cambiar la cantidad de dimensiones de sálida, esperando una mejora en las clasificaciones. 

\subsubsection{Regla de Oja - variando número de épocas}
En los primeros experimentos, fuimos probando la calidad de la clasificación utilizando solamente 100 épocas. La decisión se basó en un tema de performance de la red. Cada ejecución tenía una considerable demora, por lo que empezamos probando con pocas épocas. Mostramos los primeros resultados que obtuvimos, utilizando la regla de Oja:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_100ep_train_2.png}
  \caption{Oja - 3 dimensiones - 100 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_100ep_train_3.png}
  \caption{Oja - 3 dimensiones - 100 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\newpage

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.45]{../img/ej1/oja/oja_3salida_100ep_train.png}
  \caption{Oja - 3 dimensiones - 100 épocas - Datos Entrenamiento}
  \end{center}
\end{figure}

Éstos son los gráficos de las ejecuciones utilizando regla de Oja, con 100 épocas. Notamos que se están comenzando a formar
clusters de clasificación con distintos colores, pero que también hay mucho solapamiento en la parte central de cada vista.\\

Luego de esta etapa de entrenamiento, procesamos los datos de validación:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_100ep_validation.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_100ep_validation_3.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.65]{../img/ej1/oja/oja_3salida_100ep_validation_2.png}
  \caption{Oja - 3 dimensiones - 200 épocas - Datos Validación}
  \end{center}
\end{figure}

\newpage

Para los datos de validación vemos una dispersión muy grande. Se notan algunos puntos del mismo color agrupados levemente cerca, pero lejos
de formar una división clara.\\

Luego de obtener estos resultados, menos precisos de lo que esperábamos, decidimos intentar probar subiendo número de épocas. Observemos a continuación las mismas ejecuciones, pero subiendo el número de épocas a 200:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_train.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_train_2.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}
\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_train_3.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_train_4.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub4}
\end{subfigure}
\end{figure}

En los datos de entrenamiento se observa que con 200 épocas se empiezan a notar más visiblemente
los clusters de datos. Se observa una leve mejora en la clasificación con respecto a la versión de 100 épocas.

Podemos ver de todas formas que algunas de las categorías se encuentran mezcladas entre sí mientras otras están más claramente divididas.

A continuación los datos de validation.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_validation.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/oja/oja_3salida_200ep_validation_3.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.65]{../img/ej1/oja/oja_3salida_200ep_validation_2.png}
  \caption{Oja - 3 dimensiones - 200 épocas - Datos Validación}
  \end{center}
\end{figure}

En esta segunda tanda de gráficos se observa una mejora leve también para los datos de validación. Podemos ver que la mayoría de las marcas del mismo color están aproximadamente cercanas entre sí.

\subsubsection{Regla de Sanger - variando número de épocas}
Repetimos en este caso el experimento anterior utilizando ahora la regla de Sanger. Intentaremos comprobar si con esta nueva regla de aprendizaje
se obtienen mejores resultados variando el número de épocas.

En primer lugar, resultados con 100 épocas:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_100ep_train.png}
  \caption{Oja - 3 dimensiones - 100 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_100ep_train_3.png}
  \caption{Oja - 3 dimensiones - 100 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\newpage

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.45]{../img/ej1/sanger/sanger_3salida_100ep_train_2.png}
  \caption{Oja - 3 dimensiones - 100 épocas - Datos Entrenamiento}
  \end{center}
\end{figure}

Éstos son los gráficos de las ejecuciones utilizando regla de Oja, con 100 épocas. Notamos que se están comenzando a formar
clusters de clasificación con distintos colores, pero que también hay mucho solapamiento en la parte central de cada vista.\\

Luego de esta etapa de entrenamiento, procesamos los datos de validación:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_100ep_validation.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_100ep_validation_3.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.65]{../img/ej1/sanger/sanger_3salida_100ep_validation_2.png}
  \caption{Oja - 3 dimensiones - 200 épocas - Datos Validación}
  \end{center}
\end{figure}

\newpage

Para los datos de validación vemos una dispersión muy grande. Se notan algunos puntos del mismo color agrupados levemente cerca, pero lejos
de formar una división clara.\\

Observemos a continuación las mismas ejecuciones, pero subiendo el número de épocas a 200:

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_train.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_train_2.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}
\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_train_3.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_train_4.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub4}
\end{subfigure}
\end{figure}

En los datos de entrenamiento se observa que con 200 épocas se empiezana notar más visiblemente
los clusters de datos. Se observa una leve mejora en la clasificación con respecto a la versión de 100 épocas.

Podemos ver de todas formas que algunas de las categorías se encuentran mezcladas entre sí mientras otras están más claramente divididas.

A continuación los datos de validation.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_validation.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth, scale=1]{../img/ej1/sanger/sanger_3salida_200ep_validation_3.png}
  \caption{Oja - 3 dimensiones - 200 épocas}
  \label{fig:sub2}
\end{subfigure}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.65]{../img/ej1/sanger/sanger_3salida_200ep_validation_2.png}
  \caption{Oja - 3 dimensiones - 200 épocas - Datos Validación}
  \end{center}
\end{figure}

En esta segunda tanda de gráficos se observa una mejora leve también para los datos de validación. Podemos ver que la mayoría de las marcas del mismo color están aproximadamente cercanas entre sí.

\newpage
\subsection{Ejercicio 2}

\newpage
\section{Soluciones Óptimas Propuestas}

% Siguiendo las distintas conclusiones que fuimos formando a través de los experimentos, generamos una solución óptima para cada ejercicio del TP. Estas soluciones se encuentran codificadas en \textbf{solucion\_ej1.json} y \textbf{solucion\_ej2.json}.

% \subsection{Ejercicio 1}
% La solución del ejercicio 1 fue generada con los siguientes parámetros:

% \texttt{\$python script.py 1 -ep=250 -capas=10,10 -eta=0.05 -estop=0.1}

% La solución generó muy buenos resultados, obteniendo 94\% de efectividad con respecto a su dataset de testing.
% Con respecto al error final, así fue su evolución:

% \begin{figure}[h]
%   \begin{center}
%   \includegraphics[scale=0.50]{graficos/solucion_ej1.png}
%   \caption{Evolución del error a través del entrenamiento para la solución 1}
%   \end{center}
% \end{figure}

% Notamos que encontró valores muy bajos de error, con una curva bastante pronunciada a partir de la época 50. Observamos que el early stopping efectivamente entró en efecto, ya que cortó la ejecución antes de llegar al límite de épocas.\\

% En caso de querer cargar y probar esta red, ejecutar:

% \texttt{\$python script.py 1 -file=F -rda=solucion\_ej1.json -te=100 }

% donde \texttt{F} debe ser el path al archivo CSV que contenga el dataset seleccionado. El parámetro $te=100$ implica que se le ordena a la red predecir todos los resultados del dataset como testing y calcular su tasa de aciertos.

% \subsection{Ejercicio 2}
% La solución del ejercicio 2 fue generada con los siguientes parámetros:

% \texttt{\$python script.py 2 -ep=250 -capas=7 -estop=0.05}

% La solución generó resultados decentes, obteniendo 74\% de efectividad con respecto a su dataset de testing.\\
% Se nota una eficiencia menor a la de la solución del ejercicio 1.
% En la última figura podemos ver la evolución de las épocas y el error:

% \begin{figure}[h]
%   \begin{center}
%   \includegraphics[scale=0.50]{graficos/solucion_ej2.png}
%   \caption{Evolución del error a través del entrenamiento para la solución 2}
%   \end{center}
% \end{figure}

% \newpage

% Notamos en este caso un descenso más lento del error y un estancamiento final en la curva. No se llegó a aplicar la cláusula del early stopping.


% En caso de querer cargar y probar esta red, ejecutar:

% \texttt{\$python script.py 2 -file=F -rda=solucion\_ej2.json -te=100 }

% donde \texttt{F} debe ser el path al archivo CSV que contenga el dataset seleccionado.

% \newpage
\section{Conclusión}

% Como conclusión podemos ver que los distintos ejercicios y sus características obtuvieron diferentes resultados en los experimentos realizados.\\

% Notamos en ellos algunos fenómenos. En primer lugar, parecería que la cantidad óptima de neuronas en cada capa se acerca a la cantidad de atributos a procesar por la red. Esto se pudo observar en el experimento de cantidad de neuronas para cada ejercicios.\\
% En segundo lugar, apreciamos distintos efectos en la cantidad de épocas necesarias para llegar a buenos resultados. Cada ejercicio necesitó una cantidad diferente y muchos de los parámetros afectaron dicha cantidad, aumentándola ampliamente en varios casos.\\

% Algunos parámetros que pensamos que tendrían mayor efecto en los resultados fueron los de distribución de los pesos, momentum y en el caso del ejercicio 2, cantidad de capas. Nos sorprendió que finalmente la solución óptima no utilizara más estos factores.\\

% Aprendimos que parámetros como el early stopping, que de antemano parecía que si o si debería estar en nuestra solución, no nos dió resultados lo suficiente buenos 
% como para considerarlo como algo obligatorio a la hora de entrenar la red. Quizás esto fue porque la cantidad de épocas de nuestro entrenamiento no era la suficiente 
% como vimos anteriormente, y este relacionado también con que nuestro conjunto de datos es acotado, nuestra red pequeña y no se necesitan tantas épocas para entrenar.

% Vimos también que los parámetros adaptativos, como el learning rate, mejoran considerablemente soluciones como el entrenamiento batch o mini batch. Incluso, en el 
% entrenamiento batch, se puede llegar a conseguir una soluciones muy buenas si las épocas son suficientes con learning rate adaptativo.

% Finalmente observamos la naturaleza práctica de este tipo de problemas, en la cual muchos de las decisiones responden a experimentación y pruebas y no tanto a fundamentos teóricos o conceptuales.
